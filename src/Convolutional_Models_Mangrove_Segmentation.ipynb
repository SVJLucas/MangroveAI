{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bFpoPl8MPwBo"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT5DNsXVQgLl",
        "outputId": "bd4c760a-e2dc-4f5c-cf10-362a5744f3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpg3fuxhcQBm"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEjSQEdcJwLJ"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1aD5xV-5cKMY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import glob\n",
        "import time\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import segmentation_models_pytorch as smp\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, jaccard_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import random\n",
        "import matplotlib.colors as mcolors\n",
        "from skimage.io import imread, imshow\n",
        "\n",
        "from skimage.io import imread\n",
        "import albumentations as A\n",
        "from typing import List\n",
        "\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXRXQqeH7COi"
      },
      "outputs": [],
      "source": [
        "def set_all_seeds(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_all_seeds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3NKqrA3Ig3y2"
      },
      "outputs": [],
      "source": [
        "# DATASET\n",
        "dataset_dir = \"dataset/\"\n",
        "# ADJUST THESE 2 VALUES DEPENDING ON THE TRAINING TIME\n",
        "train_test_split = 0.5\n",
        "n_samples_per_zone = 20 # 50 recommended\n",
        "n_zones = 1 # up to 10 zones\n",
        "# Order of bands : B, G, R, nir, nir_vegetation, swir, ndvi, ndwi, ndmi\n",
        "# Keep all bands by default and reduce if training takes too long (keep a minima the first 4 + ndvi and ndmi)\n",
        "bands_to_keep = list(range(9))\n",
        "\n",
        "# MODEL\n",
        "num_channels = len(bands_to_keep)\n",
        "num_classes = 1 # Mangrove class\n",
        "encoder_name = \"resnet50\"\n",
        "encoder_weights = None\n",
        "activation = 'sigmoid' # Mangrove vs Non-Mangrove\n",
        "use_augmentation = True\n",
        "name_model = \"UNet-Resnet50\"\n",
        "model_save_path_epochs = f'model/{name_model}/epochs/'\n",
        "os.makedirs(model_save_path_epochs, exist_ok=True)\n",
        "model_save_path_metrics = f'model/{name_model}/metrics/'\n",
        "os.makedirs(model_save_path_metrics, exist_ok=True)\n",
        "\n",
        "save_interval = 1\n",
        "\n",
        "# TRAINING\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "# COMPUTATION & PRINTS (PYTORCH LIGHTNING)\n",
        "accelerator = 'gpu'\n",
        "strategy =  'auto'#'ddp' if multiple GPUs otherwise leave emtpy if single GPU training\n",
        "num_nodes = 1\n",
        "gpus_per_node = 1\n",
        "num_workers = 1\n",
        "enable_progress_bar = True\n",
        "progress_rate = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Y_V18idsnp"
      },
      "source": [
        "# Display random examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU2mbQm0OpNh"
      },
      "outputs": [],
      "source": [
        "import image_utils  # Import the image_utils module\n",
        "\n",
        "# Now you can use functions from image_utils\n",
        "path_to_2020_sentinel_images_folder = os.path.join(dataset_dir, \"satellite-images\")\n",
        "path_to_2020_masks_folder = os.path.join(dataset_dir, \"masks\")\n",
        "\n",
        "images = image_utils.get_all_file_paths(path_to_2020_sentinel_images_folder)\n",
        "masks = image_utils.get_all_file_paths(path_to_2020_masks_folder)\n",
        "\n",
        "image_utils.display_samples(images, masks, nb_samples=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "midp2J3xctdK"
      },
      "source": [
        "# Mangrove Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nhYWFXKLoVlb"
      },
      "outputs": [],
      "source": [
        "from dataset_utils import get_train_test_paths_by_zone, MangroveSegmentationDataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Get train and test paths\n",
        "full_paths_train, full_paths_test = get_train_test_paths_by_zone(dataset_dir, train_test_split, n_samples_per_zone, n_zones)\n",
        "\n",
        "# Create dataset instances\n",
        "dataset_train = MangroveSegmentationDataset(full_paths_train, bands_to_keep=bands_to_keep, use_augmentation=use_augmentation)\n",
        "dataset_test = MangroveSegmentationDataset(full_paths_test, bands_to_keep=bands_to_keep, use_augmentation=False)\n",
        "\n",
        "# Create DataLoaders\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDO2n7y6hjAH"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVNEaPvGhjoB"
      },
      "outputs": [],
      "source": [
        "# To use Unet\n",
        "model = smp.Unet(\n",
        "    encoder_name = encoder_name,\n",
        "    in_channels=num_channels,\n",
        "    activation = activation,\n",
        "    classes=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To use PAN\n",
        "\n",
        "# model = smp.PAN(\n",
        "#     encoder_output_stride=16,\n",
        "#     upsampling=4,\n",
        "#     encoder_name = encoder_name,\n",
        "#     #decoder_channels=decoder_channels,\n",
        "#     in_channels=num_channels,\n",
        "#     decoder_channels=512,\n",
        "#     activation = activation,\n",
        "#     classes=1,\n",
        "# )"
      ],
      "metadata": {
        "id": "NWHiVTfQ-eqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To use MAnet\n",
        "\n",
        "# model = smp.MAnet(\n",
        "#     encoder_name = encoder_name,\n",
        "#     encoder_depth = encoder_depth,\n",
        "#     decoder_channels=decoder_channels,\n",
        "#     in_channels=num_channels,\n",
        "#     activation = activation,\n",
        "#     classes=1,\n",
        "# )"
      ],
      "metadata": {
        "id": "wJg3dMEy-nj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS6omJOU9vUD"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    # Number of parameters in millions\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "\n",
        "count_parameters(model)\n",
        "# 32.54 for resnet50, 24.45 for resnet34, 14.34 for resnet18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb_OTt7AmzWX"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znk-qNf7m0UJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.5, verbose=False)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0cgzdbaBen8"
      },
      "outputs": [],
      "source": [
        "from train_model import train_final_model\n",
        "\n",
        "# Call the training function\n",
        "mean_loss_train, mean_f1_train, mean_iou_train, mean_accuracy_train, mean_loss_test, mean_f1_test, mean_iou_test, mean_accuracy_test, elapsed_time, best_model_filename, best_mean_iou_test = train_final_model(\n",
        "    model,\n",
        "    dataloader_train,\n",
        "    dataloader_test,\n",
        "    num_epochs,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    criterion,\n",
        "    device,\n",
        "    model_save_path_epochs,\n",
        "    save_interval\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upxzQKntCYjh"
      },
      "outputs": [],
      "source": [
        "print(f\"Elapsed time of {elapsed_time} seconds for {num_epochs} epochs => best test IOU = {best_mean_iou_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzqQ6fCye6vv"
      },
      "outputs": [],
      "source": [
        "from train_model import save_metrics_to_file\n",
        "\n",
        "lists = {\n",
        "    \"mean_loss_train\": mean_loss_train,\n",
        "    \"mean_f1_train\": mean_f1_train,\n",
        "    \"mean_iou_train\": mean_iou_train,\n",
        "    \"mean_accuracy_train\": mean_accuracy_train,\n",
        "    \"mean_loss_test\": mean_loss_test,\n",
        "    \"mean_f1_test\": mean_f1_test,\n",
        "    \"mean_iou_test\": mean_iou_test,\n",
        "    \"mean_accuracy_test\": mean_accuracy_test,\n",
        "    \"elapsed_time\": elapsed_time,\n",
        "    \"best_model_filename\": best_model_filename,\n",
        "    \"best_mean_iou_test\": best_mean_iou_test\n",
        "}\n",
        "\n",
        "save_metrics_to_file(lists, model_save_path_metrics+\"metrics.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiipxGy1mGpC"
      },
      "source": [
        "# Plot training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDhyCzQsgjSM"
      },
      "outputs": [],
      "source": [
        "import plot_training_results\n",
        "\n",
        "# Plot training and validation loss\n",
        "plot_training_results.plot_train_val_loss(mean_loss_train, mean_loss_test)\n",
        "\n",
        "# Plot training and validation IOU score\n",
        "plot_training_results.plot_train_val_iou(mean_iou_train, mean_iou_test)\n",
        "\n",
        "# Plot training and validation F1 score\n",
        "plot_training_results.plot_train_val_f1(mean_f1_train, mean_f1_test)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plot_training_results.plot_train_val_acc(mean_accuracy_train, mean_accuracy_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVD2yeq4nB9z"
      },
      "source": [
        "# Plot segmentation results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV_bfExkpbqU"
      },
      "source": [
        "## Show inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2nmoVKIjj6o",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from plot_segmentation_results import plot_augmented_images\n",
        "\n",
        "# Save images and mask\n",
        "save_bands = f'model/{name_model}/plots_bands'\n",
        "os.makedirs(save_bands, exist_ok=True)\n",
        "\n",
        "# Call the function to plot augmented images\n",
        "batch = next(iter(dataloader_test))\n",
        "for idx, (test_image, true_mask) in enumerate(zip(batch[0], batch[1])):\n",
        "    test_image_np = test_image.permute(1, 2, 0).cpu().detach().numpy()\n",
        "    true_mask_np = true_mask.cpu().detach().numpy().squeeze().astype('int')\n",
        "    plot_augmented_images(test_image_np, true_mask_np, idx, save_bands)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VqcSVJCpdkH"
      },
      "source": [
        "## Show predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJrrgjYImCKk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from plot_segmentation_results import plot_segmentation_results\n",
        "\n",
        "# SHOW PREDICTIONS ON FULL BATCH\n",
        "save_comparisons = f'model/{name_model}/plots_comparison'\n",
        "os.makedirs(save_comparisons, exist_ok=True)\n",
        "\n",
        "batch = next(iter(dataloader_test))\n",
        "best_model = model\n",
        "plot_segmentation_results(batch, device, model_save_path_epochs, best_model, best_model_filename, save_comparisons)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "G9Y_V18idsnp",
        "midp2J3xctdK",
        "DDO2n7y6hjAH",
        "lb_OTt7AmzWX",
        "IiipxGy1mGpC",
        "wVD2yeq4nB9z"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}